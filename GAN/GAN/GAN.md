# GANê³¼ ì‹œê°ì§€ëŠ¥
###### <strong> GANì˜ ê¸°ë³¸ - Vanilla GAN

* ì–¸ì–´ : Python
* í”„ë¡œê·¸ë¨ : Colab
* ì†ŒìŠ¤ì½”ë“œ : GAN.ipynb
* ì‚¬ìš©í•œ ëª¨ë“ˆ : matplotlib, torch, torchvison, tqdm
* ì£¼ìš” í•¨ìˆ˜ :

```

 gen_block, dis_block, class Generator, class Discriminator, get_gen_loss, get_disc_loss, show_tensor_images
 
 ```
 

----------------------------------------

## ë°ì´í„°

* MNIST

----------------------------------------

## GAN
 
### GANì˜ ê¸°ë³¸ì›ë¦¬
 
 * ì ëŒ€ì  íƒìƒ‰(Adversarial search) : ì„œë¡œ ë°˜ëŒ€ë˜ëŠ” ë‘ ì…ì¥ì˜ ê°ì²´ê°€ ì„œë¡œ ì…ì¥ì„ ë°”ê¿”ê°€ë©° ì§„í–‰í•¨ìœ¼ë¡œì¨ ìµœì ì˜ í•´ë¥¼ íƒìƒ‰í•˜ëŠ” ê³¼ì •
 
 * Discriminator Model(Classifier) : ì…ë ¥ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ì •ì˜í•œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜
   * SVM -> CNN
   * ì…ë ¥ : ë³µì¡í•œ ëª¨ë¸ ex) ì˜ìƒ
   * ì¶œë ¥ : í•˜ë‚˜ì˜ scalar or n ê°œì˜ class
 
 * Generative Model : ê°„ë‹¨í•œ ì •ë³´(latent vector)ë¡œë¶€í„° ë³µì¡í•œ ëª¨ë¸ì„ í•©ì„±í•˜ëŠ” ë„êµ¬
   * AE(Auto Encoder) -> VAE(Variational Auto Encoder)
   * ì…ë ¥ : ê°„ë‹¨í•œ ì •ë³´(latent vector)
   * ì¶œë ¥ : ì˜ìƒ
 
 <p align="center"><img src = "https://user-images.githubusercontent.com/72690336/122800405-dbbbaa00-d2fd-11eb-8688-a05e8eaef6b1.png" width="80%" height="80%">

  
### GANì˜ ê°œë…
  
  * ìƒì„±ì (Generator)ì™€ íŒë³„ì (Discriminator)ì˜ ëŒ€ë¦½ê³¼ ê²½ìŸì„ í†µí•´ì„œ ëª¨ë¸ì„ í›ˆë ¨ì‹œì¼œì„œ ì‚¬ìš©ìê°€ ë§Œì¡±í• ë§Œí•œ ìˆ˜ì¤€ì˜ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ìƒì„± ëª¨ë¸
  * ìƒì„±ì (Generator)
    * G::p<sub>z</sub>(z) -> p<sub>g</sub>
    * ëŒ€ë¦½ì„ í†µí•´ ë” ìš°ìˆ˜í•œ í’ˆì§ˆì˜ ê²°ê³¼ ë„ì¶œí•˜ë„ë¡ í›ˆë ¨
  * íŒë³„ì (Discriminator)
    * D::D(x;ğœƒ<sub>d</sub> -> fake/real
    * ìƒì„±ìì˜ ê²°ê³¼ê°€ ë§Œì¡±í•  ìˆ˜ì¤€ì¸ì§€ë¥¼ íŒë³„í•˜ì—¬ fake/realì˜ ê²°ê³¼ ë„ì¶œ
   * x ~ p<sub>g</sub> -> fake, x ~ data -> real
  * GANì˜ í›ˆë ¨ì´ ëë‚˜ë©´ ë§ˆì§€ë§‰ parameter(ğœƒ<sub>g</sub>)ë¥¼ ì €ì¥í•œ generatorë¥¼ ì´ìš©í•´ì„œ ë‹¤ì–‘í•œ ìƒ˜í”Œ ìƒì„±
  
 <p align="center"><img src = "https://user-images.githubusercontent.com/72690336/122802940-f7747f80-d300-11eb-8afb-6524d4d1a7df.png" width="40%" height="40%">
  
### GANì˜ êµ¬ì„±ìš”ì†Œ
  * ìƒì„±ì(Generator)
    * Decoderì™€ ìœ ì‚¬í•œ êµ¬ì¡°
    * ì…ë ¥(latent vector)ë¥¼ ë°›ì•„ì„œ ê²°ê³¼(synthesized image)ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë“ˆ
    * Vanilla Ganì—ì„œëŠ” convolutionì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
  
  * Generatorì˜ êµ¬ì¡°
    * nê°œì˜ generator block ìœ¼ë¡œ êµ¬ì„±
    * generator blockì€ ë‚®ì€ í•´ìƒë„ì˜ ì…ë ¥ì„ ë°›ì•„ì„œ ë†’ì€ í•´ìƒë„ì˜ ì¶œë ¥ì„ ìƒì„±
  
  <p align="center"><img src = "https://user-images.githubusercontent.com/72690336/122803575-bdf04400-d301-11eb-8764-c1f8b0faf957.png" width="70%" height="70%">
  
  * íŒë³„ì(Discriminator)
    * ì…ë ¥(real or fake data)ì„ ë°›ì•„ì„œ real/fakeë¥¼ íŒì •í•˜ëŠ” ëª¨ë“ˆ
    * Classifierì™€ ìœ ì‚¬í•œ ì—­í• ì„ ìˆ˜í–‰
   
  * Discriminatorì˜ êµ¬ì¡°
    * nê°œì˜ discriminator block ìœ¼ë¡œ êµ¬ì„±
    * discriminator blockì€ ë†’ì€ í•´ìƒë„ì˜ ì…ë ¥ì„ ë°›ì•„ì„œ ë‚®ì€ í•´ìƒë„ì˜ ì¶œë ¥ì„ ìƒì„±
   
   <p align="center"><img src = "https://user-images.githubusercontent.com/72690336/122804041-58e91e00-d302-11eb-974e-995c385319db.png" width="70%" height="70%">
    
  * GAN Loss í•¨ìˆ˜
    * BCE(Binary Cross Entropyì—ì„œ ë„ì¶œ
    * í›ˆë ¨ë°ì´í„° (real, x) -> y<sup>(i)</sup> = 1
    * ìƒì„±ë°ì´í„° (fake, G(z)) -> y<sup>(i)</sup> = 0, x<sup>(i)</sup> = G(z<sup>(i)</sup>, ğœƒ<sub>g</sub>)
    * Discriminator -> h(.,ğœƒ<sub>d</sub>
    * BCEì™€ì˜ ì°¨ì´ : BCEëŠ” ìµœëŒ€í™”í•˜ëŠ” ğœƒ í•˜ë‚˜ë¥¼ ì°¾ëŠ” ë¬¸ì œë¡œ max ë°©í–¥ìœ¼ë¡œë§Œ ìµœì í™” í•˜ê¸° ë•Œë¬¸ì— í›ˆë ¨ì´ ì‰¬ìš°ë‚˜, GAN LossëŠ” maxì™€ min ë°©í–¥ìœ¼ë¡œ ìµœì í™”í•˜ê¸° ë•Œë¬¸ì— í›ˆë ¨ì´ ì–´ë ¤ì›€
      * Discriminator: D(x)ëŠ” 1ì„, D(G(z))ëŠ” 0ì„ ì¶œë ¥í•  ê²ƒ -> logD(x) & log (1 â€“ D(G(z)))ê°€ max
      * Generator: D(G(z))ê°€ 1ì„ ì¶œë ¥í•  ê²ƒ -> log(1 â€“ D(G(z)))ê°€ min
    
    <p align="center"><img src = "https://user-images.githubusercontent.com/72690336/122806282-1bd25b00-d305-11eb-89df-08d747d637ae.png" width="70%" height="70%">

    
### GAN Training
  * í›ˆë ¨ ëª©í‘œ
    * í›ˆë ¨ ë°ì´í„° xì™€ ì¼ì¹˜í•˜ëŠ” G(z)ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒ P<sub>data</sub> = P<sub>z</sub>, ì˜ ìƒì„±ë˜ë©´ D()ëŠ” xì™€ G(z)ë¥¼ êµ¬ë¶„í•˜ì§€ ëª»í•¨ = ê°’ : 1/2
    * GANì€ min max V(G,D)ë¥¼ ì¶”êµ¬í•˜ê¸° ë•Œë¬¸ì— ìˆ˜ë ´ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆì§€ë§Œ, ìµœì ì˜ ê²½ìš°ì— ìˆ˜ë ´ë˜ëŠ” ê°’ì´ ìˆìŒì„ ì¦ëª…
    
  * í›ˆë ¨ì˜ ì–´ë ¤ì›€
    * Dì™€ Gë¥¼ ë™ì‹œì— í›ˆë ¨í•´ì•¼í•¨ : DëŠ” max, GëŠ” minì„ ì¶”êµ¬
    * í›ˆë ¨ ì´ˆê¸° ìƒì„±ë˜ëŠ” G(z)ëŠ” í’ˆì§ˆì´ ì•ˆì¢‹ì€ -> ë§¤ë²ˆ 0ì— ê°€ê¹Œìš°ë©´ log(1-D(G(z))ì´ 0ì— ê°€ê¹Œìš´ ê°’ì„ ê°€ì§ -> gradient descentë¥¼ ì ìš©í•˜ê¸° í˜ë“¦
    * ìœ„ì™€ ê°™ì€ ë¬¸ì œì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì´ˆê¸°ì—ëŠ” log(1-D(G(z))ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ê³  D(G(z))ë¥¼ ìµœëŒ€í™” ì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ í›ˆë ¨(í›„ìê°€ ê°’ì´ ë” í¬ë‹¤)

---------------------------------------------


### ì½”ë“œ ì„¤ëª…

* generator block
   ```python
      def gen_block(input_dim, output_dim):
       return nn.Sequential(
         nn.Linear(input_dim, output_dim),
         nn.BatchNorm1d(output_dim),
         nn.ReLU(inplace=True),
       )
     ```
  * input ì°¨ì›ê³¼ output ì°¨ì›ì„ ì…ë ¥ë°›ìŒ
  * Linear layerì™€ batch norm, relu í•¨ìˆ˜ë¡œ êµ¬ì„±
     
* Generator
     ```python
        class Generator(nn.Module):
         def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):
           super(Generator, self).__init__()
           # Build the neural network
           self.gen = nn.Sequential(
               gen_block(z_dim, hidden_dim),
               gen_block(hidden_dim, hidden_dim*2),
               gen_block(hidden_dim*2, hidden_dim*4),
               gen_block(hidden_dim*4, hidden_dim*8),

               nn.Linear(hidden_dim*8, im_dim),
               nn.Sigmoid()
           )
     ```
  * 4ê°œì˜ generator blockê³¼ FC layer, sigmoid í•¨ìˆ˜ë¡œ êµ¬ì„±
  * MNISTë°ì´í„° ì…ë ¥(28x28)
    * ì…ë ¥ : z_dim = 10
    * ì¶œë ¥ : im_dim = 784
     
* discriminator block
   ```python
      def dis_block(input_dim, output_dim):
       return nn.Sequential(
         nn.Linear(input_dim, output_dim),
         nn.LeakyReLU(0.2, inplace=True)
       )
     ```
  * input ì°¨ì›ê³¼ output ì°¨ì›ì„ ì…ë ¥ë°›ìŒ
  * Linear layerì™€ relu í•¨ìˆ˜ë¡œ êµ¬ì„±
     
* Discriminator
  ```python
     class Discriminator(nn.Module):
      def __init__(self, im_dim=784, hidden_dim=128):
        super(Discriminator, self).__init__()
        self.disc = nn.Sequential(
            dis_block(im_dim, hidden_dim * 4),
            dis_block(hidden_dim * 4, hidden_dim * 2),
            dis_block(hidden_dim * 2, hidden_dim),
            nn.Linear(hidden_dim, 1)
        )
     ```
  * 3ê°œì˜ discriminator blockê³¼ FC layerë¡œ êµ¬ì„±
  * MNISTë°ì´í„° ì…ë ¥(28x28)
    * ì…ë ¥ : im_dim = 784
    * ì¶œë ¥ : 1
     
* ì´í›„ Loss Function ì •ì˜, ì´ˆê¸°í™”, Optimizer ìƒì„±, ëª¨ë¸ Training ìˆœìœ¼ë¡œ ì§„í–‰
     
     <p align="center"><img src = "https://user-images.githubusercontent.com/72690336/122808601-0dd20980-d308-11eb-89b8-32fa62903301.png" width="30%" height="30%">
      
      
### ìƒ˜í”Œ ì´ë¯¸ì§€
* ì›ë³¸ ì´ë¯¸ì§€(real)
      
<p align="center"><img src = "https://user-images.githubusercontent.com/72690336/122808816-4eca1e00-d308-11eb-8eb3-ab3a3777fcd6.png" width="30%" height="30%">

* ìƒì„±ì´ë¯¸ì§€(fake)
 
<p align="center"><img src = "https://user-images.githubusercontent.com/72690336/122809052-8df86f00-d308-11eb-863f-3ab343d2f733.png" width="30%" height="30%">
 
* ëª¨ë¸ ì„±ëŠ¥(step 6000)
  * Generator loss: 3.7584004163742075, discriminator loss: 0.07491180759668352

